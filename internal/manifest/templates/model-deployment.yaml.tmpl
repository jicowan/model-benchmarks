apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ .Name }}
  namespace: {{ .Namespace }}
  labels:
    app.kubernetes.io/name: {{ .Name }}
    app.kubernetes.io/component: model-server
    accelbench/role: model
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: {{ .Name }}
  template:
    metadata:
      labels:
        app.kubernetes.io/name: {{ .Name }}
        app.kubernetes.io/component: model-server
        accelbench/role: model
    spec:
      terminationGracePeriodSeconds: 30
      tolerations:
{{- if eq .AcceleratorType "gpu" }}
        - key: nvidia.com/gpu
          operator: Exists
          effect: NoSchedule
{{- else }}
        - key: aws.amazon.com/neuron
          operator: Exists
          effect: NoSchedule
{{- end }}
      nodeSelector:
        node.kubernetes.io/instance-type: {{ .InstanceTypeName }}
      containers:
        - name: vllm
{{- if eq .AcceleratorType "gpu" }}
          image: vllm/vllm-openai:{{ .FrameworkVersion }}
{{- else }}
          image: vllm/vllm-neuron:{{ .FrameworkVersion }}
{{- end }}
          ports:
            - name: http
              containerPort: 8000
              protocol: TCP
          env:
            - name: HF_TOKEN
              value: "{{ .HfToken }}"
          args:
            - "--model"
            - "{{ .ModelHfID }}"
            - "--port"
            - "8000"
            - "--tensor-parallel-size"
            - "{{ .TensorParallelDegree }}"
            - "--trust-remote-code"
{{- if eq .Quantization "fp16" }}
            - "--dtype"
            - "float16"
{{- else if eq .Quantization "int8" }}
            - "--quantization"
            - "bitsandbytes"
            - "--load-format"
            - "bitsandbytes"
{{- else if eq .Quantization "int4" }}
            - "--quantization"
            - "gptq"
{{- end }}
{{- if gt .MaxModelLen 0 }}
            - "--max-model-len"
            - "{{ .MaxModelLen }}"
{{- end }}
          resources:
            requests:
              cpu: {{ .CPURequest }}
              memory: {{ .MemoryRequest }}
{{- if eq .AcceleratorType "gpu" }}
              nvidia.com/gpu: "{{ .AcceleratorCount }}"
            limits:
              nvidia.com/gpu: "{{ .AcceleratorCount }}"
{{- else }}
              aws.amazon.com/neuron: "{{ .AcceleratorCount }}"
            limits:
              aws.amazon.com/neuron: "{{ .AcceleratorCount }}"
{{- end }}
          readinessProbe:
            httpGet:
              path: /health
              port: http
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 60
          startupProbe:
            httpGet:
              path: /health
              port: http
            initialDelaySeconds: 30
            periodSeconds: 10
            failureThreshold: 120
          livenessProbe:
            httpGet:
              path: /health
              port: http
            periodSeconds: 30
            timeoutSeconds: 5
            failureThreshold: 3
---
apiVersion: v1
kind: Service
metadata:
  name: {{ .Name }}
  namespace: {{ .Namespace }}
  labels:
    app.kubernetes.io/name: {{ .Name }}
    app.kubernetes.io/component: model-server
spec:
  type: ClusterIP
  ports:
    - name: http
      port: 8000
      targetPort: http
      protocol: TCP
  selector:
    app.kubernetes.io/name: {{ .Name }}
